<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Causal Inference From a Bayesian Perspective!</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
		<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
	</head>
	<body class="is-preload">
		<style>
		  .header-dark {background:#1f2936; color:white; padding:10px;}
		</style>
		
		<!-- Wrapper -->
			<div id="wrapper">
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About Me</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="header-dark">
									Introducing Bayesian Causal Inference
								</header>
								<p>In this project, we provide a brief overview of the Bayesian perspective of causal inference based on the potential outcomes framework. The first part of the project deals with reviewing causal estimands, assumptions and the general structure of Bayesian inference of causal effects. The second part deals with Bayesian Non-parametric Modeling for Causal Inference using Bayesian Additive Regression Trees (BARTs) which are claimed to handle a large number of predictors and heterogeneous treatment effects.</p>
								<p> The "Fundamental Problem of Causal Inference" inherently potrays causal inference as a missing data problem. The Bayesian paradigm is well equipped to handle the structurally missing potential outcomes as it considers the unobserved potential outcomes as unobserved random variables (viewed as unknown parameters). The entire methodology revolves around specifying a model on all random variables, including the potential outcomes, treatment and covariates. From the posterior predictive distributions of the parameters and the unobserved potential outcomes, we can draw inference on the causal estimands which are functions of model parameters, covariates and potential outcomes. The main reason for switching to Bayesian is that the Bayesian approach offers several advantages for Causal Inference. First of all, it is a rigorous inferential framework with automatic uncertainty quantification without relying on large sample approximations. Thus, it makes studying problems with small sample size or having individual treatment effects, hierarchical or network data simpler. Secondly, it naturally incorporates prior knowledge into causal analysis problems encountered frequently in evaluating spatially correlated exposures. Finally, high-dimensional Bayesian methods, like Bayesian non-paramteric models (to be studied later in this project) provide new tools for analyzing complex data. Inspite of these clear advantages, Causal Inference is dominated still by the frequentist mindset with tools like randomization tests, propensity scores etc. The paucity of thorough appraisal of the current Bayesian Causal Inference literature involving opportunities unique to the Bayesian paradigm motivates me to reflect upon this topic.</p>
								<header class="header-dark">
									Assumptions, Estimands and Setup
								</header>
								<p> <b>The Setup:</b> We focus on the simple instance where we have a binary treatment that can be easily extended to multiple treatments. Consider a sample of units drawn from a target population, indexed by \( i \in \{1,2,...,N\} \). Let \( W_i \) be the binary variable indicating \( W_i=1 \) for active treatment and \( W_i=0 \) for control. For unit \( i \), a vector of \( p \) pre-treatment covariates \( X_i \) are observed at baseline, and an outcome \( Y_i \) is observed after the treatment. Thus, there are four quantities associated with each sampled unit: \( Y_i(0),Y_i(1),W_i,X_i \), out of which three are observed - \( W_i, Y_i^{\text{obs}}=Y_i (W_i), X_i \) and one is missing - \( Y_i ^{\text{mis}}=Y_i(1-W_i) \). Given \( W_i \), there is a bijection between \( (Y_i ^{\text{obs}}, Y_i ^{\text{mis}}) \) and \( Y_i (0), Y_i (1)) \) as \( Y_i ^{\text{obs}} = Y_i(1)W_i + Y_i(0)(1-W_i) \). </p> 
								<p> <b>Causal Estimand under consideration:</b> <br>
									<ul>
										<!--
										<li> Population average treatment effect (PATE): \( \tau^{\text{PATE}} = E[Y_i(1)-Y_i(0)] \) </li>
										<li> Sample average treatment effect (SATE): \( \tau^{\text{SATE}} = \frac{1}{N} \sum_{i=1}^{N} [Y_i(1)-Y_i(0)] \) </li>
										<li> Average treatment effect for the treated (ATT): \( \tau^{\text{ATT}} = E[Y_i(1)-Y_i(0)|W_i=1] \) <\/i> -->
										<li> Conditional average treatment effect (CATE): \(\tau(x)=E[Y_i(1)-Y_i(0)|X_i=x] \) </li>
									</ul>
								    Thus, causal estimands \( \tau=\tau(Y(0),Y(1)) \) can be represented as functions \( \tau= \tau(Y^{\text{obs}},Y^{\text{obs}},W) \). <a href="https://www.jstor.org/stable/pdf/2958688.pdf">Rubin (1978)</a> shows that assuming unit-exchangeability, there exists an unknown parameter vector \( \theta \) with prior distribution \(p(\theta)\) such that $$P(Y(0),Y(1),W,X)=\int \prod_i P(Y_i(0),Y_i(1),W_i,X_i|\theta)p(\theta) d\theta $$. </p>
								<p> In order to perform Bayesian inference of the estimand \( \tau = \tau(Y^{\text{obs}},Y^{\text{obs}},W) \), we obtain the joint posterior predictive distributions of \(Y^{\text{mis}}, \theta\), and thus \(Y^{\text{mis}}\) and eventually \( \tau \). Then we can factorize the joint distribution into: $$P(Y_i(0),Y_i(1),W_i,X_i|\theta)=P(W_i|Y_i(0),Y_i(1),X_i,\theta_W)P(Y_i(0),Y_i(1)|X_i,\theta_Y)P(X_i|\theta_X) $$. Now let us list the assumptions: <br>
									<ol>
										<li> (<b> Positivity </b>): \(0 < P(W_i=1|X_i,Y_i(0),Y_i(1))<1 \) for all \( i \). </li>
										<li> (<b> Ignorability </b>): \( P(W_i=1|X_i,Y_i(0),Y_i(1))=P(W_i=1|X_i) \). </li>
										<li> <b> SUTVA </b> </li>
										<li> A priori distinct and independent parameters for \( \theta_W, \theta_Y \) </li>
										<li> (<b> Ignorable assignment </b>): \(P(W_i|Y_i(0),Y_i(1),X_i)=P(W_i|X_i) \) </li>
									</ol>
								Under the last two assumptions, the joint posterior distribution of \( (Y^{\text{mis}}, \theta_Y) \) is $$P(Y^{\text{mis}},\theta_Y | Y^{\text{obs}},W,X) \propto p(\theta_Y)\prod_{i=1}^{N} P(Y_i(0),Y_i(1)|X_i, \theta_Y) $$ The terms \( P(W_i|X_i, \theta_W) \) and \(P(X_i|\theta_X)\) drop out of the likelihood as they are not informative about \( \theta_Y \) or \(Y^{\text{mis}}\). Thus, all we need is to specify the model: \(P(Y_i(0),Y_i(1)|X_i) \). </p>
								<header class="header-dark">
									Strategies to simulate \( Y^{\text{mis}} \)
								</header>
								<p> A brief overview of the sampling scheme is mentioned here. Minute details will be added later. Resorting to Gibbs Sampling for Data Augmentation:
									<ol>
										<li> Iteratively simulate \( Y^{\text{mis}} \) and \( \theta \)  from \(P(Y^{\text{mis}}|Y^{\text{obs}},W,X,\theta) \) and \(P(\theta|Y^{\text{mis}},Y^{\text{obs}},W,X) \). </li>
										<li> Posterior predictive distribution of \(Y^{\text{mis}} \): $$P(Y^{\text{mis}}|Y^{\text{obs}},W,X,\theta) \propto \prod_{i:W_i=1} P(Y_i(0)|Y_i(1),X_i,\theta_Y) \prod_{i:W_i=0} P(Y_i(1)|Y_i(0),X,\theta_Y)$$ </li>
										<li> Impute missing potential outcomes for treated units and control units. </li>
										<li> Imputation dependes on the model \(P(Y_i(1),Y_i(0)|X_i) \). </li>
									</ol>
								This sampling strategy is not leakproof and requires modification. There is another sampling scheme called <b> Transparent Parametrization </b> which solves the problem of having no clear separation of identified and non-identified parameters in case of Gibbs sampling. After obtaining the posterior draws of \( (Y^{\text{mis}},\theta_Y) \), the next step is to calculate the posterior distribution of the causal estimand which we will discuss in detail later! </p>
								<header class="header-dark">
									Motivation for using BART in estimating Causal Effects
								</header>
								<p> In the second half of this project, I follow the lines of <a href="https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162"> Hill (2010)</a>'s approach towards Bayesian Non-parametric modeling using BART. It has gained recognition since the BART algorithm is easy to implement and requires no information about how the outcome, treatment assignment and confounding covariates are parametrically related. It can detect iteractions and non-linearities in the response surface which allows it to identifying heterogeneous treatment effects. </p>
								<p> <b> Setup: </b> We aim to estimate a model for the outcome \( Y \) , specified as \(Y=f(z,x)+\epsilon \), where \(z \) denotes the assigned treatment and \( x \)  denotes the observed confounding covariates and \( \epsilon \sim N(0,\sigma^2) \). If ignorability holds conditional on \( x \), that is \( Y(0),Y(1) \) is independent of  \( Z|X=x \), then let \(E[Y(0)]|X=x]=E[Y|Z=0,X=x]=f(0,x) \) and \( E[Y(1)|X=x]=E[Y|Z=1,X=x]=f(1,x) \). BART has some potentially important advantages over alternative methods such as random forests, boosting, and neural nets (<a href="https://hastie.su.domains/Papers/ESLII.pdf"> ESLR (2003) </a>). Harping on the advantages of using BART  for Causal Inference:
									<ul>
										<li> BART’s performance using the default prior is highly competitive in terms of prediction with other methods that rely on cross-validation to tune algorithm parameters (<a href="https://www.jstor.org/stable/27801587#metadata_info_tab_contents"> Chipman (2007) </a>). </li>
										<li> BART can handle very large numbers of predictors. </li>
										<li> In case of missing outcome data, we can have a straightforward solution under the assumption of a missing-at-random missing data mechanism by simply fitting the BART model to the complete case sample but make predictions for the full sample. </li>
									</ul>
								</p>
							</section>

					</div>

				<!-- Footer 
					<footer id="footer">
						<section>
							<form method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="text" name="email" id="email" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="3"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><input type="submit" value="Send Message" /></li>
								</ul>
							</form>
						</section>
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>1234 Somewhere Road #87257<br />
								Nashville, TN 00000-0000</p>
							</section>
							<section>
								<h3>Phone</h3>
								<p><a href="#">(000) 000-0000</a></p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">info@untitled.tld</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer> -->

				<!-- Copyright 					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div> -->

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
